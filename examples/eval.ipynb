{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Nov 28 2023 23:52:03\n"
     ]
    }
   ],
   "source": [
    "from articulate_anything.utils.metric import compute_link_placement_result, analyze_link_placement_by_type, compute_joint_pred_result, analyze_joint_pred_by_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"results\"\n",
    "dataset_dir = \"datasets/partnet-mobility-v0/dataset\"\n",
    "strategy=\"gt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/10/meta.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m link_diffs \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_link_placement_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m type_results \u001b[38;5;241m=\u001b[39m analyze_link_placement_by_type(link_diffs)\n",
      "File \u001b[0;32m~/code/articulate-anything-cleanup/articulate_anything/utils/metric.py:323\u001b[0m, in \u001b[0;36mcompute_link_placement_result\u001b[0;34m(result_dir, strategy, task_name, iter_num, get_max, dataset_dir)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strategy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 323\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpick_best_link_gt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miter_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miter_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_max\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;66;03m# Assume worst case for gt strategy\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/code/articulate-anything-cleanup/articulate_anything/utils/metric.py:225\u001b[0m, in \u001b[0;36mpick_best_link_gt\u001b[0;34m(obj_dir, iter_num, get_max)\u001b[0m\n\u001b[1;32m    223\u001b[0m best_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    224\u001b[0m best_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 225\u001b[0m obj_type \u001b[38;5;241m=\u001b[39m \u001b[43mextract_obj_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iter_num \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     iter_nums \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;28mint\u001b[39m(iter_num\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    229\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m iter_num \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(link_placement_dir)\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m iter_num\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miter_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(link_placement_dir, iter_num))\n\u001b[1;32m    232\u001b[0m     ]\n",
      "File \u001b[0;32m~/code/articulate-anything-cleanup/articulate_anything/utils/partnet_utils.py:26\u001b[0m, in \u001b[0;36mextract_obj_type\u001b[0;34m(input_dir)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_obj_type\u001b[39m(input_dir):\n\u001b[1;32m     25\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m join_path(input_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m     j \u001b[38;5;241m=\u001b[39m \u001b[43mload_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m j[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_cat\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/code/articulate-anything-cleanup/articulate_anything/utils/utils.py:41\u001b[0m, in \u001b[0;36mload_json\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_json\u001b[39m(filename):\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/10/meta.json'"
     ]
    }
   ],
   "source": [
    "link_diffs = compute_link_placement_result(result_dir, strategy=strategy,)\n",
    "type_results = analyze_link_placement_by_type(link_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_diffs = compute_joint_pred_result(result_dir, strategy=strategy)\n",
    "joint_results = analyze_joint_pred_by_type(joint_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from articulate_anything.utils.partnet_utils import track_obj_types, sample_obj_id\n",
    "from collections import Counter\n",
    "\n",
    "def filter_objects_by_link_diff(link_diffs, threshold=0.05):\n",
    "    return [obj_id for obj_id, data in link_diffs.items() if data['link_diff']['average_diff'] < threshold]\n",
    "\n",
    "def sample_proportional_to_category_size_filtered(real2code_categories, num_samples, filtered_obj_ids):\n",
    "    obj_types = track_obj_types()\n",
    "    \n",
    "    # Filter obj_types to only include objects in filtered_obj_ids\n",
    "    filtered_obj_types = {cat: [obj for obj in objs if obj in filtered_obj_ids] \n",
    "                          for cat, objs in obj_types.items()}\n",
    "    \n",
    "    total_objects = sum(len(filtered_obj_types[cat]) for cat in real2code_categories if cat in filtered_obj_types)\n",
    "    \n",
    "    if total_objects == 0:\n",
    "        raise ValueError(\"No objects meet the filtering criteria\")\n",
    "    \n",
    "    sampled_objects = []\n",
    "    for category in real2code_categories:\n",
    "        if category in filtered_obj_types:\n",
    "            proportion = len(filtered_obj_types[category]) / total_objects\n",
    "            num_category_samples = int(num_samples * proportion)\n",
    "            category_samples = random.sample(filtered_obj_types[category], \n",
    "                                             min(num_category_samples, len(filtered_obj_types[category])))\n",
    "            sampled_objects.extend(category_samples)\n",
    "    \n",
    "    # Add any remaining samples due to rounding\n",
    "    while len(sampled_objects) < num_samples:\n",
    "        category = random.choice([cat for cat in real2code_categories if cat in filtered_obj_types])\n",
    "        remaining_objects = [obj for obj in filtered_obj_types[category] if obj not in sampled_objects]\n",
    "        if remaining_objects:\n",
    "            extra_sample = random.choice(remaining_objects)\n",
    "            sampled_objects.append(extra_sample)\n",
    "        else:\n",
    "            break  # Break if we've exhausted all available objects\n",
    "    \n",
    "    return sampled_objects\n",
    "\n",
    "def train_val_split_filtered(real2code_categories, num_trains, num_vals, link_diffs):\n",
    "    total_samples = num_trains + num_vals\n",
    "    \n",
    "    # Filter objects based on link difference\n",
    "    filtered_obj_ids = filter_objects_by_link_diff(link_diffs)\n",
    "    \n",
    "    # Sample all objects at once\n",
    "    all_samples = sample_proportional_to_category_size_filtered(real2code_categories, total_samples, filtered_obj_ids)\n",
    "    \n",
    "    # Shuffle the samples\n",
    "    random.shuffle(all_samples)\n",
    "    \n",
    "    # Split into train and val sets\n",
    "    train_samples = all_samples[:num_trains]\n",
    "    val_samples = all_samples[num_trains:]\n",
    "    \n",
    "    return train_samples, val_samples\n",
    "\n",
    "def print_category_distribution(obj_ids, real2code_categories, set_name):\n",
    "    category_counts = Counter()\n",
    "    obj_types = track_obj_types()\n",
    "    for obj_id in obj_ids:\n",
    "        for category in real2code_categories:\n",
    "            if obj_id in obj_types.get(category, []):\n",
    "                category_counts[category] += 1\n",
    "                break\n",
    "        else:\n",
    "            category_counts['Other'] += 1\n",
    "    \n",
    "    total_objects = len(obj_ids)\n",
    "    print(f\"Distribution of objects per category ({set_name} set):\")\n",
    "    print(\"-------------------------------------\")\n",
    "    for category in real2code_categories:\n",
    "        count = category_counts[category]\n",
    "        percentage = (count / total_objects) * 100 if total_objects > 0 else 0\n",
    "        print(f\"{category}: {count} ({percentage:.2f}%)\")\n",
    "    if category_counts['Other'] > 0:\n",
    "        other_count = category_counts['Other']\n",
    "        other_percentage = (other_count / total_objects) * 100 if total_objects > 0 else 0\n",
    "        print(f\"Other: {other_count} ({other_percentage:.2f}%)\")\n",
    "    print(f\"Total: {total_objects}\")\n",
    "\n",
    "# Usage\n",
    "real2code_categories = [\"StorageFurniture\", \"Laptop\", \"Box\", \"Table\", \"Refrigerator\"]\n",
    "num_trains = 467\n",
    "num_vals = 35\n",
    "\n",
    "# Assuming link_diffs is already computed\n",
    "train_obj_ids, val_obj_ids = train_val_split_filtered(real2code_categories, num_trains, num_vals, link_diffs)\n",
    "\n",
    "print_category_distribution(train_obj_ids, real2code_categories, \"Training\")\n",
    "print(\"\\n\")\n",
    "print_category_distribution(val_obj_ids, real2code_categories, \"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tasks_from_joint_diffs(joint_diffs, sample_set):\n",
    "    tasks = []\n",
    "    for key, value in joint_diffs.items():\n",
    "        obj_id, joint_id, semantic_joint_id = key\n",
    "        if obj_id in sample_set and value[\"failure_reason\"] == \"success\":\n",
    "            task = {\n",
    "                \"obj_id\": obj_id,\n",
    "                \"joint_id\": joint_id,\n",
    "                \"semantic_joint_id\": semantic_joint_id,\n",
    "                \"joint_diff\": value,\n",
    "                \"link_diff\": link_diffs[obj_id],\n",
    "            }\n",
    "            tasks.append(task)\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tasks = generate_tasks_from_joint_diffs(joint_diffs, train_obj_ids)\n",
    "val_tasks = generate_tasks_from_joint_diffs(joint_diffs, val_obj_ids)\n",
    "len(train_tasks), len(val_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from articulate_anything.utils.utils import save_json\n",
    "save_json(train_tasks, \"train_tasks.json\")\n",
    "save_json(val_tasks, \"val_tasks.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "articulate-anything-clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
